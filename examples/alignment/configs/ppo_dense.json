{
  "model_name_or_path": "HuggingFaceH4/smolLM2-135M-SFT-Only",
  "dataset_name": "mlabonne/Orca-Mini-DPO",
  "dataset_split": "train[:200]",
  "prompt_column": "prompt",
  "chosen_column": "chosen",
  "rejected_column": "rejected",
  "max_prompt_length": 512,
  "max_response_length": 256,
  "output_dir": "outputs/ppo_dense",
  "log_with": null,
  "load_in_8bit": true,
  "reward_config": {
    "model_name_or_path": "",
    "learning_rate": 5e-6,
    "num_train_epochs": 1,
    "per_device_train_batch_size": 2
  },
  "per_device_train_batch_size": 2,
  "gradient_accumulation_steps": 4,
  "learning_rate": 1e-5,
  "num_train_epochs": 1,
  "ppo_batch_size": 8,
  "target_kl": 0.1,
  "dense_rewards": true,
  "generation_samples": 64,
  "max_ppo_steps": 32,
  "verbosity_word_limit": 60,
  "test_prompts_file": "examples/alignment/prompts.txt"
}
